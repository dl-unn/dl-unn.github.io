# Постановка задачи

Требуется решить задачу классификации изображений на 10 классов c использованием нейронных сетей.

# Датасет

CIFAR-10: https://www.cs.toronto.edu/~kriz/cifar.html

# Ограничения

Реализация обучаемого классификатора на базе нейронной сети дожна быть выполнена самостоятельно на языке Python.
Можно использовать только встроенный функционал и базовые операции над векторами и матрицами из библиотеки Numpy 
(нельзя использовать автоматическое дифференцирование).

Необходимо самостоятельно реализовать:
  1. Слои для прямого хода и обратного распространения ошибки;
  2. Оптимизатор, поддерживающий батчи (модификация SGD);
  3. Метод инициалиазации весов нейронной сети (тренировка должна выполнять со "случайных" весов).
  4. Подходящую функцию потерь.

Нейронная сеть должна состоять минимум из 2х скрытых слоев с функцией активации. Несколько примеров:
  1. Image -> Fully connected (X outputs) -> Sigmoid -> Fully connected (Y outputs) -> Sigmoid -> Fully connected (10 outputs) -> Sigmoid -> Loss.
  2. Image -> Convolution (X output channels) -> ReLU -> Convolution (Y output channels) -> ReLU -> Fully connected (10 outputs) -> Softmax -> Loss. 

# Шаблон

[task2_template](task2_template.ipynb)

# Рекомендации к выполнению задания

1. Выполнить реализацию нейронной сети, слоёв, активаций, оптимизатора, методов аугментации данных.
Раздел `2. NN implementation, layers, activations, loss functions and optimizer` в шаблоне `task2_template.ipynb`.
2. Проверить корректности реализованной сети.
Сеть должна быстро переобучаться при тренировке на 1ой картинке, на 10ти картинках.
Раздел `3. Check correctness` в шаблоне `task2_template.ipynb`.
3. Выполнить тренировку нейронной сети (не забывайте про изменение LR).
Раздел `4. Experiments` в шаблоне `task2_template.ipynb`.
4. Указать наилучшую архитектуру и достигнутое качество на тестовом датасете.
Раздел `5. Results` в шаблоне `task2_template.ipynb`.

# Критерий выполнения задания

1. Выполнена реализация обучаемой нейронной сети для задачи классификации изображений.
2. Нейронная сеть содержит минимум 2 скрытых слоя (см. выше), одну функцию активации и реализацию модификации SGD. 
3. Получено качество на тестовом датасете CIFAR-10, заполнены все поля в разделе `5. Results` (шаблон `task2_template.ipynb`).

# При формировании оценки будут учитываться

1. Достигнутое качество на тестовом датасете.
2. Сложность используемых слоёв (будет плюсом, если реализовать Convolution, BathNorm, ReLU, ELU, Depthwise convolution и др.).

# Сдача работы

1. Необходимо отправить письмо с заголовком "Deep Learning - Task 2" на e-mail alexey.sidnev@gmail.com.
2. К письму необходимо прекрепить ipynb (все внешние зависимости должны быть указаны в notebook'е) и pdf/html с решением задачи.
Файлы должны называться `ФамилияИмя.ipynb`, `ФамилияИмя.html`, например: `SidnevAlexey.ipynb`.
3. Необходимо создать Pull Request в репозиторий `https://github.com/dl-unn/dl-unn.github.io` с указанием архитектуры сети и достигнутого качества (файл [results](task2_results.md)). 

Deadline: 23:59 7.11.2020