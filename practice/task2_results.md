# Results of Task 2

| Name                  | Test accuracy, %  | NN architecture|
|-----------------------|-------------------|----------------|
| Gladyshev Alexey      |       67.53       | 1. Conv2D(3x3, ReLU, stride=1, out=64)<br>2. MaxPool(2x2, stride=1)<br>3. BatchNormalization()<br>4.Conv2D(3x3, ReLU, stride=1, out=128)<br>5. MaxPool(2x2, stride=1)<br>6. BatchNormalization()<br>7. Conv2D(3x3, ReLU, stride=1, out=256)<br>8. MaxPool(2x2, stride=1)<br>9. BatchNormalization()<br>10. Flatten()<br>11. Dense(ReLU, out=128)<br>12. Dropout(0.7)<br>13. BatchNormalization()<br>14. Dense(ReLU, out=512)<br>15. Dropout(0.7)<br>16. BatchNormalization()<br>17. Dense(ReLU, out=1024)<br>18. Dropout(0.7)<br>19. BatchNormalization()<br>20. Softmax() |
| Batanina Liubov       |       66.75       | 1. Conv2D(3x3, ReLU, padding="same", stride=1, out=32)<br>2. MaxPooling(2x2, stride=2)<br>3. BatchNormalization()<br>4. Conv2D(3x3, ReLU, padding="same", stride=1, out=64)<br>5. MaxPooling(2x2, stride=2)<br>6. BatchNormalization()<br>7. Conv2D(3x3, ReLU, padding="same", stride=1, out=128)<br>8. MaxPooling(2x2, stride=2)<br>9. BatchNormalization()<br>10. Flatten()<br>11. Fully connected(ReLU, out=128)<br>12. Dropout(0.1)<br>13. Fully connected (out=10)<br>14. Softmax |
| Kulikova Svetlana     |       63.33       | 1. Conv2D(5x5, ReLU, stride=1, out=32)<br>2. BatchNormalization()<br>3. MaxPooling(2x2, stride=2)<br>4. Conv2D(5x5, ReLU, stride=1, out=64)<br>5. BatchNormalization()<br>6. MaxPooling(2x2, stride=2)<br>7. Conv2D(5x5, ReLU, stride=1, out=128)<br>8. Flatten()<br>9. Dense(ReLU, out=92)<br>10. Dense(out=10)<br>11. Softmax |
| Krasikova Ekaterina   |       62.92       | 1. Conv2D(3x3, ReLU, stride=1, out=8)<br>2. Conv2D(3x3, ReLU, stride=1, out=16)<br>3. MaxPool(2x2)<br>4. Conv2D(3x3, ReLU, stride=1, out=32)<br>5. Conv2D(3x3, ReLU, stride=1, out=32)<br>6. MaxPool(2x2)<br>7. Fully connected (out=400)<br>8. Fully connected (out=10)<br>9. Softmax |
| Kamelina Julia        |       61.24       | 1. Conv2D(5x5, ReLU, stride=1, out=8)<br>2. MaxPooling(2x2, stride=2)<br>3. Conv2D(3x3, ReLU, stride=1, out=16)<br>4. MaxPooling(2x2, stride=2)<br>5. Fully connected(ReLU, out=288)<br>6. Fully connected(ReLU, out=10)<br>7. Softmax |
| Kuznetsov Vladislav   |       59.66       | 1. Fully connected (out=700), ReLU<br>2. Fully connected (out=300), ReLU<br>3. Fully connected (out=10)<br>4. Softmax |
| Senyaev Andrey        |       56.00       | 1. Conv2D(3x3, LeakyReLU, stride=2, out=32)<br>2. Conv2D(3x3, LeakyReLU, stride=2, out=64)<br>3. Flatten<br>4. Fully connected (100, sigmoid)<br>5. Fully connected (10, softmax)  |
| Panov Aleksandr       |       55.05       | 1. Fully connected(leakyReLU, out=768)<br>2. Fully connected(leakyReLU, out=96)<br>3. Fully connected(ReLU, out=10)<br>4. Softmax |
| Tarakanov Kirill      |       54.79       | 1. Fully connected(out=256, activation=sigmoid)<br>2. Fully connected(out=128, activation=sigmoid)<br>3. Fully connected (out=10)<br>4. Softmax |
| Mayachkin Arseny      |       54.70       | 1. Fully Connected(size=100) - Affine-Batchnorm-ReLu <br>2. Fully Connected(size=100) - Softmax |
| Okunev Boris          |       54.00       | 1. Fully connected (out=256, ReLU)<br>2. Fully connected (out=64, ReLU)<br>3. Fully connected (out=10)<br>4. Softmax |
| Zinoviev Vladimir     |       53.91       | 1. Fully connected (out=400)<br>2. ReLU<br>3. Fully connected (out=10)<br>4. ReLU<br>5. Softmax |
| Degtyarev Anton       |       53.44       | 1. Flatten()<br>2. FullyConnected(units=1024), Elu<br>3. FullyConnected(units=512), Elu<br>4. FullyConnected(units=10)<br>5. Softmax |
| Kuznetsov Konstantin  |       53.37       | 1. Conv2D(3x3, ReLU, stride=1, out=16)<br>2. MaxPool(2x2)<br>3. Conv2D(3x3, ReLU, stride=1, out=16)<br>4. MaxPool(2x2)<br>5. Flatten()<br>6. Dense(ReLU, out=100)<br>7. Dense(ReLU, out=10)<br>8. Softmax |
| Panova Elena          |       53.00       | 1. Fully connected (out=256)<br>2. Batch normalisation<br>3. LeakyReLu(alpha=0.1)<br>4. Fully connected (out=64)<br>5. Batch normalisation<br>6. LeakyReLu(alpha=0.1)<br>7. Fully connected (out=10)<br>8. Batch normalisation<br>9. Softmax |
| Romanov Alexander     |       52.18       | 1. Fully connected (ReLU, out=250)<br>2. Fully connected (ReLU, out=100)<br>3. Fully connected (ReLU, out=10)<br> 4. Softmax |
| Israfilov Marat       |       51.02       | 1. Fully connected (ReLU, out=1024)<br>2. Fully connected (ReLU, out=512)<br>3. Fully connected (ReLU, out=256)<br>4. Fully connected (out=10)<br>5. Softmax |
| Protas Maria          |       49.58       | 1. Fully Connected (ReLU, out=100) <br>2. Fully Connected (ReLU, out=30) <br>3. Fully Connected (out=10) <br>4. Softmax |
| Rodionov Fedor        |       49.50       | 1. Fully connected (out=256), ReLU <br>2. Fully connected (out=64), ReLU <br>3. Fully connected (out=10), ReLU <br>4. Softmax |
| Tarasov Oleg          |       46.99       | 1. Fully connected (input=1024, output=512)<br>2. ReLU<br>3. Fully connected (input=512, output=256)<br>4. ReLU<br>5. Fully connected (input=256, output=10)<br>6. Softmax |
| Senina Anastasia      |       46.23       | 1. Conv2D(5x5, ReLU, stride=1, out=12)<br>2. Conv2D(3x3, ReLU, stride=1, out=24)<br>3.Fully connected (out=10)<br>5. Softmax |
| Gribov Pavel          |       46.00       | 1. Fully connected (out=1024, sigmoid)<br>2. Fully connected (out=512, sigmoid)<br>3. Fully connected (out=256, sigmoid)<br>4.Fully connected (out=10, sigmoid)<br>5. Softmax() |
| Nechesanov Vladimir   |       45.70       | 1. DenseLayer (3072, 100)<br>2. Sigmoid()<br>3. DenseLayer (100, 200)<br>4. Sigmoid()<br>5. DenseLayer (200, 100)<br>6. Sigmoid()<br>7. DenseLayer(100, 10) |
| Daniil Roman          |       45.40       | 1. Fully connected (out=100, ReLU)<br>2. Fully connected (out=200, ReLU)<br>3. Fully connected (out=100, ReLU)<br>4.Fully connected (out=10, ReLU)<br>5. Softmax() |
| Usova Marina          |       45.38       | 1. Fully connected (out=1024), tanh<br>2. Fully connected (out=512), tanh<br>3. Fully connected (out=256), tanh<br>4. Fully connected (out=10), tanh<br>5. Softmax |
| Kuznetsov Victor      |       45.18       | 1. Fully connected (out=1100), ReLU <br>2. Fully connected (out=1100), ReLU <br>3. Fully connected (out=10), ReLU <br>4. Softmax |
| Shkenev Petr          |       43.70       | 1. Conv2D(3x3, Leaky ReLU, stride=2, out=32)<br>2. Conv2D(3x3, Leaky ReLU, stride=2, out=64)<br>3. Conv2D(3x3, Leaky ReLU, stride=2, out=64)<br>4. Conv2D(3x3, Leaky ReLU, stride=2, out=128)<br>5. Fully connected (Leaky ReLU, out=64)<br>6. Fully connected (Leaky ReLU, out=32)<br>7. Fully connected (Leaky ReLU, out=10)<br>8. Softmax |
